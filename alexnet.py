# -*- coding: utf-8 -*-
"""alexnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j9SQBpXFD_ajuxfYVncnX_a5FBBF4MdY
"""

import tensorflow as tf

tf.__version__

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense, BatchNormalization, Activation

# alexnet = 5 CNN + 3 FC
def alexnet(img_shape=(227,227,3), n_classes=1000):
  alexnet = Sequential()
  
  alexnet.add(Conv2D(96, 11, (4,4), input_shape=img_shape))
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  alexnet.add(MaxPool2D(3, 2)) # 1. 27*27*96, overlapped pooling
  
  alexnet.add(Conv2D(256, 5, 1, 'same'))
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  alexnet.add(MaxPool2D(3, 2)) # 2. 13*13*256
  
  alexnet.add(Conv2D(384, 3, 1, 'same')) # 3. 13*13*384
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  
  alexnet.add(Conv2D(384, 3, 1, 'same')) # 4. 13*13*384
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  
  alexnet.add(Conv2D(256, 3, 1, 'same')) # 13*13*256
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  alexnet.add(MaxPool2D(3, 2)) # 5. 6*6*256, overlapped pooling
  
  alexnet.add(Flatten())
  alexnet.add(Dense(4096)) # 6. 4096
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  alexnet.add(Dropout(0.5))
  
  alexnet.add(Dense(4096)) # 7. 4096
  alexnet.add(BatchNormalization())
  alexnet.add(Activation('relu'))
  alexnet.add(Dropout(0.5))
  
  alexnet.add(Dense(n_classes, activation='softmax')) # 8. 1000
  
  return alexnet

model = alexnet()
model.summary()

